#!/usr/bin/env python3
"""
TS2Vec vs T-Rep Performance Benchmark

ë²¤ì¹˜ë§ˆí¬ í•­ëª©:
1. ê²€ìƒ‰ ì •í™•ë„ (Precision@K, Recall@K)
2. ê²€ìƒ‰ ì†ë„
3. ì„ë² ë”© ìƒì„± ì†ë„
4. ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰
5. ìœ ì‚¬ë„ ë¶„í¬
"""

import sys
import os
sys.path.insert(0, '/home/0_code/NIER_Pipelines')

import chromadb
from chromadb.config import Settings
import numpy as np
import pandas as pd
import time
import json
from tqdm import tqdm
import logging
from datetime import datetime

from NIERModules.chroma_ts2vec import Ts2VecEmbedding
from NIERModules.chroma_trep import TRepEmbedding

logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# ì „ì—­ ì„¤ì •
DB_PATH = "/home/0_code/RAG/ChromaDB/ts2vec_embedding_function/NIER_DB"
TEST_DATA_PATH = "/home/0_code/RAG/ts2vec/datasets/NIER/NIER_v2_TEST.csv"
ELEMENTS = ["SO2", "O3", "CO", "NO", "NO2"]
DEVICE = "cuda"
NUM_QUERIES = 50  # ê° ì›ì†Œë‹¹ ì¿¼ë¦¬ ìˆ˜

# ëª¨ë¸ ê²½ë¡œ
TS2VEC_MODEL_PATHS = {
    "SO2": "/home/0_code/RAG/ts2vec/training/v0_1_1__v0_1_1_SO2_20250427_213952/model.pkl",
    "O3": "/home/0_code/RAG/ts2vec/training/v0_1_1__v0_1_1_O3_20250427_213507/model.pkl",
    "CO": "/home/0_code/RAG/ts2vec/training/v0_1_1__v0_1_1_CO_20250427_210220/model.pkl",
    "NO": "/home/0_code/RAG/ts2vec/training/v0_1_1__v0_1_1_NO_20250427_212025/model.pkl",
    "NO2": "/home/0_code/RAG/ts2vec/training/v0_1_1__v0_1_1_NO2_20250427_212740/model.pkl"
}

TREP_MODEL_PATHS = {
    "SO2": "/home/0_code/NIER_Pipelines/NIERModules/chroma_trep/model_pkl/model_SO2.pt",
    "O3": "/home/0_code/NIER_Pipelines/NIERModules/chroma_trep/model_pkl/model_O3.pt",
    "CO": "/home/0_code/NIER_Pipelines/NIERModules/chroma_trep/model_pkl/model_CO.pt",
    "NO": "/home/0_code/NIER_Pipelines/NIERModules/chroma_trep/model_pkl/model_NO.pt",
    "NO2": "/home/0_code/NIER_Pipelines/NIERModules/chroma_trep/model_pkl/model_NO2.pt"
}


class BenchmarkRunner:
    def __init__(self):
        self.client = chromadb.PersistentClient(
            path=DB_PATH,
            settings=Settings(anonymized_telemetry=False)
        )
        
        self.ts2vec_collection = self.client.get_collection("time_series_collection")
        self.trep_collection = self.client.get_collection("time_series_collection_trep")
        
        # í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ
        logger.info(f"í…ŒìŠ¤íŠ¸ ë°ì´í„° ë¡œë“œ: {TEST_DATA_PATH}")
        self.test_data = pd.read_csv(TEST_DATA_PATH)
        logger.info(f"  ì „ì²´ ë ˆì½”ë“œ: {len(self.test_data)}")
        logger.info(f"  ì›ì†Œë³„ ë¶„í¬:")
        for elem in ELEMENTS:
            count = len(self.test_data[self.test_data['element'] == elem])
            logger.info(f"    {elem}: {count}ê°œ")
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        self.ts2vec_models = self._init_ts2vec_models()
        self.trep_models = self._init_trep_models()
        
        # ë²¤ì¹˜ë§ˆí¬ ê²°ê³¼ ì €ì¥
        self.results = {
            "timestamp": datetime.now().isoformat(),
            "config": {
                "test_data": TEST_DATA_PATH,
                "num_queries_per_element": NUM_QUERIES,
                "device": DEVICE
            },
            "ts2vec": {},
            "trep": {},
            "comparison": {}
        }
    
    def _init_ts2vec_models(self):
        """TS2Vec ëª¨ë¸ ì´ˆê¸°í™”"""
        logger.info("TS2Vec ëª¨ë¸ ì´ˆê¸°í™”...")
        models = {}
        for elem in ELEMENTS:
            logger.info(f"  {elem}: {TS2VEC_MODEL_PATHS[elem]}")
            models[elem] = Ts2VecEmbedding(
                weight_path=TS2VEC_MODEL_PATHS[elem],
                device=DEVICE,
                encoding_window='full_series'
            )
        logger.info("TS2Vec ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
        return models
    
    def _init_trep_models(self):
        """T-Rep ëª¨ë¸ ì´ˆê¸°í™”"""
        logger.info("T-Rep ëª¨ë¸ ì´ˆê¸°í™”...")
        models = {}
        for elem in ELEMENTS:
            logger.info(f"  {elem}: {TREP_MODEL_PATHS[elem]}")
            models[elem] = TRepEmbedding(
                weight_path=TREP_MODEL_PATHS[elem],
                device=DEVICE,
                encoding_window='full_series',
                time_embedding='t2v_sin'
            )
        logger.info("T-Rep ëª¨ë¸ ì´ˆê¸°í™” ì™„ë£Œ")
        return models
    
    def benchmark_embedding_speed(self):
        """ì„ë² ë”© ìƒì„± ì†ë„ ë²¤ì¹˜ë§ˆí¬"""
        logger.info("=" * 60)
        logger.info("1. ì„ë² ë”© ìƒì„± ì†ë„ ë²¤ì¹˜ë§ˆí¬")
        logger.info("=" * 60)
        
        results = {"ts2vec": {}, "trep": {}}
        
        for elem in ELEMENTS:
            logger.info(f"\nì›ì†Œ: {elem}")
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ í•´ë‹¹ ì›ì†Œ ìƒ˜í”Œ ì¶”ì¶œ
            elem_data = self.test_data[self.test_data['element'] == elem]
            if len(elem_data) == 0:
                logger.warning(f"  {elem}: í…ŒìŠ¤íŠ¸ ë°ì´í„° ì—†ìŒ")
                continue
            
            samples = elem_data['values'].head(NUM_QUERIES).tolist()
            
            # TS2Vec
            ts2vec_times = []
            for ts in tqdm(samples, desc=f"TS2Vec {elem}", leave=False):
                start = time.time()
                _ = self.ts2vec_models[elem]([ts])
                ts2vec_times.append(time.time() - start)
            
            # T-Rep
            trep_times = []
            for ts in tqdm(samples, desc=f"T-Rep {elem}", leave=False):
                start = time.time()
                _ = self.trep_models[elem]([ts])
                trep_times.append(time.time() - start)
            
            results["ts2vec"][elem] = {
                "mean_ms": float(np.mean(ts2vec_times) * 1000),
                "std_ms": float(np.std(ts2vec_times) * 1000),
                "median_ms": float(np.median(ts2vec_times) * 1000),
                "min_ms": float(np.min(ts2vec_times) * 1000),
                "max_ms": float(np.max(ts2vec_times) * 1000)
            }
            
            results["trep"][elem] = {
                "mean_ms": float(np.mean(trep_times) * 1000),
                "std_ms": float(np.std(trep_times) * 1000),
                "median_ms": float(np.median(trep_times) * 1000),
                "min_ms": float(np.min(trep_times) * 1000),
                "max_ms": float(np.max(trep_times) * 1000)
            }
            
            speedup = np.mean(ts2vec_times) / np.mean(trep_times)
            
            logger.info(f"  TS2Vec: {np.mean(ts2vec_times)*1000:.2f} Â± {np.std(ts2vec_times)*1000:.2f} ms")
            logger.info(f"  T-Rep:  {np.mean(trep_times)*1000:.2f} Â± {np.std(trep_times)*1000:.2f} ms")
            logger.info(f"  ì†ë„ í–¥ìƒ: {speedup:.2f}x")
        
        self.results["ts2vec"]["embedding_speed"] = results["ts2vec"]
        self.results["trep"]["embedding_speed"] = results["trep"]
        
        return results
    
    def benchmark_search_speed(self, k_values=[1, 5, 10]):
        """ê²€ìƒ‰ ì†ë„ ë²¤ì¹˜ë§ˆí¬"""
        logger.info("=" * 60)
        logger.info("2. ê²€ìƒ‰ ì†ë„ ë²¤ì¹˜ë§ˆí¬")
        logger.info("=" * 60)
        
        results = {"ts2vec": {}, "trep": {}}
        
        for elem in ELEMENTS:
            logger.info(f"\nì›ì†Œ: {elem}")
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ì¿¼ë¦¬ ì¶”ì¶œ
            elem_data = self.test_data[self.test_data['element'] == elem]
            if len(elem_data) == 0:
                logger.warning(f"  {elem}: í…ŒìŠ¤íŠ¸ ë°ì´í„° ì—†ìŒ")
                continue
            
            queries = elem_data['values'].head(min(20, len(elem_data))).tolist()
            
            results["ts2vec"][elem] = {}
            results["trep"][elem] = {}
            
            for k in k_values:
                # TS2Vec
                ts2vec_times = []
                for query in tqdm(queries, desc=f"TS2Vec {elem} k={k}", leave=False):
                    try:
                        embedding = self.ts2vec_models[elem]([query])[0]
                        start = time.time()
                        _ = self.ts2vec_collection.query(
                            query_embeddings=[embedding.tolist()],
                            n_results=k,
                            where={"element": elem}
                        )
                        ts2vec_times.append(time.time() - start)
                    except Exception as e:
                        logger.error(f"TS2Vec ê²€ìƒ‰ ì—ëŸ¬: {e}")
                
                # T-Rep
                trep_times = []
                for query in tqdm(queries, desc=f"T-Rep {elem} k={k}", leave=False):
                    try:
                        embedding = self.trep_models[elem]([query])[0]
                        start = time.time()
                        _ = self.trep_collection.query(
                            query_embeddings=[embedding.tolist()],
                            n_results=k,
                            where={"element": elem}
                        )
                        trep_times.append(time.time() - start)
                    except Exception as e:
                        logger.error(f"T-Rep ê²€ìƒ‰ ì—ëŸ¬: {e}")
                
                if not ts2vec_times or not trep_times:
                    continue
                
                results["ts2vec"][elem][f"k{k}"] = {
                    "mean_ms": float(np.mean(ts2vec_times) * 1000),
                    "std_ms": float(np.std(ts2vec_times) * 1000)
                }
                
                results["trep"][elem][f"k{k}"] = {
                    "mean_ms": float(np.mean(trep_times) * 1000),
                    "std_ms": float(np.std(trep_times) * 1000)
                }
                
                speedup = np.mean(ts2vec_times) / np.mean(trep_times) if np.mean(trep_times) > 0 else 0
                
                logger.info(f"  k={k}:")
                logger.info(f"    TS2Vec: {np.mean(ts2vec_times)*1000:.2f} Â± {np.std(ts2vec_times)*1000:.2f} ms")
                logger.info(f"    T-Rep:  {np.mean(trep_times)*1000:.2f} Â± {np.std(trep_times)*1000:.2f} ms")
                logger.info(f"    ì†ë„ í–¥ìƒ: {speedup:.2f}x")
        
        self.results["ts2vec"]["search_speed"] = results["ts2vec"]
        self.results["trep"]["search_speed"] = results["trep"]
        
        return results
    
    def benchmark_storage_size(self):
        """ì €ì¥ ê³µê°„ ë²¤ì¹˜ë§ˆí¬"""
        logger.info("=" * 60)
        logger.info("3. ì €ì¥ ê³µê°„ ë²¤ì¹˜ë§ˆí¬")
        logger.info("=" * 60)
        
        # Collection í¬ê¸° ê³„ì‚°
        ts2vec_count = self.ts2vec_collection.count()
        trep_count = self.trep_collection.count()
        
        # ì„ë² ë”© ì°¨ì›
        ts2vec_dim = 320
        trep_dim = 128
        
        # ì˜ˆìƒ í¬ê¸° (float32 ê¸°ì¤€)
        ts2vec_size = ts2vec_count * ts2vec_dim * 4 / (1024**2)  # MB
        trep_size = trep_count * trep_dim * 4 / (1024**2)  # MB
        
        results = {
            "ts2vec": {
                "count": ts2vec_count,
                "dimension": ts2vec_dim,
                "estimated_size_mb": float(ts2vec_size)
            },
            "trep": {
                "count": trep_count,
                "dimension": trep_dim,
                "estimated_size_mb": float(trep_size)
            },
            "reduction_percent": float((1 - trep_size / ts2vec_size) * 100) if ts2vec_size > 0 else 0
        }
        
        logger.info(f"\nTS2Vec Collection:")
        logger.info(f"  ë ˆì½”ë“œ ìˆ˜: {ts2vec_count:,}")
        logger.info(f"  ì°¨ì›: {ts2vec_dim}")
        logger.info(f"  ì˜ˆìƒ í¬ê¸°: {ts2vec_size:.2f} MB")
        
        logger.info(f"\nT-Rep Collection:")
        logger.info(f"  ë ˆì½”ë“œ ìˆ˜: {trep_count:,}")
        logger.info(f"  ì°¨ì›: {trep_dim}")
        logger.info(f"  ì˜ˆìƒ í¬ê¸°: {trep_size:.2f} MB")
        
        logger.info(f"\nì €ì¥ ê³µê°„ ì ˆê°: {results['reduction_percent']:.1f}%")
        
        self.results["comparison"]["storage"] = results
        
        return results
    
    def benchmark_similarity_distribution(self):
        """ìœ ì‚¬ë„ ë¶„í¬ ë²¤ì¹˜ë§ˆí¬"""
        logger.info("=" * 60)
        logger.info("4. ìœ ì‚¬ë„ ë¶„í¬ ë¶„ì„")
        logger.info("=" * 60)
        
        results = {"ts2vec": {}, "trep": {}}
        
        for elem in ELEMENTS:
            logger.info(f"\nì›ì†Œ: {elem}")
            
            # í…ŒìŠ¤íŠ¸ ë°ì´í„°ì—ì„œ ì¿¼ë¦¬ ì¶”ì¶œ
            elem_data = self.test_data[self.test_data['element'] == elem]
            if len(elem_data) == 0:
                logger.warning(f"  {elem}: í…ŒìŠ¤íŠ¸ ë°ì´í„° ì—†ìŒ")
                continue
            
            queries = elem_data['values'].head(min(10, len(elem_data))).tolist()
            
            ts2vec_distances = []
            trep_distances = []
            
            for query in tqdm(queries, desc=f"{elem} ìœ ì‚¬ë„ ë¶„ì„", leave=False):
                # TS2Vec
                try:
                    embedding = self.ts2vec_models[elem]([query])[0]
                    ts2vec_result = self.ts2vec_collection.query(
                        query_embeddings=[embedding.tolist()],
                        n_results=10,
                        where={"element": elem}
                    )
                    if 'distances' in ts2vec_result and ts2vec_result['distances']:
                        ts2vec_distances.extend(ts2vec_result['distances'][0])
                except Exception as e:
                    logger.error(f"TS2Vec ìœ ì‚¬ë„ ë¶„ì„ ì—ëŸ¬: {e}")
                
                # T-Rep
                try:
                    embedding = self.trep_models[elem]([query])[0]
                    trep_result = self.trep_collection.query(
                        query_embeddings=[embedding.tolist()],
                        n_results=10,
                        where={"element": elem}
                    )
                    if 'distances' in trep_result and trep_result['distances']:
                        trep_distances.extend(trep_result['distances'][0])
                except Exception as e:
                    logger.error(f"T-Rep ìœ ì‚¬ë„ ë¶„ì„ ì—ëŸ¬: {e}")
            
            if ts2vec_distances and trep_distances:
                results["ts2vec"][elem] = {
                    "mean": float(np.mean(ts2vec_distances)),
                    "std": float(np.std(ts2vec_distances)),
                    "min": float(np.min(ts2vec_distances)),
                    "max": float(np.max(ts2vec_distances))
                }
                
                results["trep"][elem] = {
                    "mean": float(np.mean(trep_distances)),
                    "std": float(np.std(trep_distances)),
                    "min": float(np.min(trep_distances)),
                    "max": float(np.max(trep_distances))
                }
                
                logger.info(f"  TS2Vec ê±°ë¦¬: {np.mean(ts2vec_distances):.4f} Â± {np.std(ts2vec_distances):.4f}")
                logger.info(f"  T-Rep ê±°ë¦¬:  {np.mean(trep_distances):.4f} Â± {np.std(trep_distances):.4f}")
        
        self.results["comparison"]["similarity_distribution"] = results
        
        return results
    
    def run_all_benchmarks(self):
        """ëª¨ë“  ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰"""
        logger.info("ğŸš€ ë²¤ì¹˜ë§ˆí¬ ì‹œì‘")
        logger.info(f"ë‚ ì§œ: {datetime.now().strftime('%Y-%m-%d %H:%M:%S')}")
        logger.info(f"ë””ë°”ì´ìŠ¤: {DEVICE}")
        logger.info(f"ì›ì†Œ: {', '.join(ELEMENTS)}")
        logger.info("")
        
        try:
            # 1. ì„ë² ë”© ìƒì„± ì†ë„
            self.benchmark_embedding_speed()
            
            # 2. ê²€ìƒ‰ ì†ë„
            self.benchmark_search_speed()
            
            # 3. ì €ì¥ ê³µê°„
            self.benchmark_storage_size()
            
            # 4. ìœ ì‚¬ë„ ë¶„í¬
            self.benchmark_similarity_distribution()
            
        except Exception as e:
            logger.error(f"ë²¤ì¹˜ë§ˆí¬ ì‹¤í–‰ ì¤‘ ì—ëŸ¬: {e}")
            import traceback
            traceback.print_exc()
        
        return self.results
    
    def save_results(self, output_path="/home/0_code/NIER_Pipelines/scripts/benchmark_results.json"):
        """ê²°ê³¼ ì €ì¥"""
        with open(output_path, 'w', encoding='utf-8') as f:
            json.dump(self.results, f, indent=2, ensure_ascii=False)
        logger.info(f"\nâœ… ê²°ê³¼ ì €ì¥: {output_path}")
    
    def generate_report(self, output_path="/home/0_code/NIER_Pipelines/scripts/benchmark_report.md"):
        """ë§ˆí¬ë‹¤ìš´ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = f"""# TS2Vec vs T-Rep ë²¤ì¹˜ë§ˆí¬ ë¦¬í¬íŠ¸

**ìƒì„± ì¼ì‹œ**: {self.results['timestamp']}  
**ë””ë°”ì´ìŠ¤**: {DEVICE}  
**í…ŒìŠ¤íŠ¸ ë°ì´í„°**: {TEST_DATA_PATH}  
**í…ŒìŠ¤íŠ¸ ì›ì†Œ**: {', '.join(ELEMENTS)}  
**ì›ì†Œë‹¹ ì¿¼ë¦¬ ìˆ˜**: {NUM_QUERIES}

---

## 1. ì„ë² ë”© ìƒì„± ì†ë„

| ì›ì†Œ | TS2Vec (ms) | T-Rep (ms) | ì†ë„ í–¥ìƒ |
|------|-------------|------------|----------|
"""
        
        if "embedding_speed" in self.results["ts2vec"]:
            for elem in ELEMENTS:
                if elem in self.results["ts2vec"]["embedding_speed"]:
                    ts2vec_mean = self.results["ts2vec"]["embedding_speed"][elem]["mean_ms"]
                    trep_mean = self.results["trep"]["embedding_speed"][elem]["mean_ms"]
                    speedup = ts2vec_mean / trep_mean if trep_mean > 0 else 0
                    report += f"| {elem} | {ts2vec_mean:.2f} | {trep_mean:.2f} | {speedup:.2f}x |\n"
        
        report += "\n---\n\n## 2. ê²€ìƒ‰ ì†ë„ (k=10)\n\n| ì›ì†Œ | TS2Vec (ms) | T-Rep (ms) | ì†ë„ í–¥ìƒ |\n|------|-------------|------------|----------|\n"
        
        if "search_speed" in self.results["ts2vec"]:
            for elem in ELEMENTS:
                if elem in self.results["ts2vec"]["search_speed"] and "k10" in self.results["ts2vec"]["search_speed"][elem]:
                    ts2vec_mean = self.results["ts2vec"]["search_speed"][elem]["k10"]["mean_ms"]
                    trep_mean = self.results["trep"]["search_speed"][elem]["k10"]["mean_ms"]
                    speedup = ts2vec_mean / trep_mean if trep_mean > 0 else 0
                    report += f"| {elem} | {ts2vec_mean:.2f} | {trep_mean:.2f} | {speedup:.2f}x |\n"
        
        report += "\n---\n\n## 3. ì €ì¥ ê³µê°„\n\n"
        
        if "storage" in self.results["comparison"]:
            storage = self.results["comparison"]["storage"]
            report += f"""
| ëª¨ë¸ | ë ˆì½”ë“œ ìˆ˜ | ì°¨ì› | í¬ê¸° (MB) |
|------|----------|------|----------|
| TS2Vec | {storage['ts2vec']['count']:,} | {storage['ts2vec']['dimension']} | {storage['ts2vec']['estimated_size_mb']:.2f} |
| T-Rep | {storage['trep']['count']:,} | {storage['trep']['dimension']} | {storage['trep']['estimated_size_mb']:.2f} |

**ì €ì¥ ê³µê°„ ì ˆê°**: {storage['reduction_percent']:.1f}%
"""
        
        report += "\n---\n\n## 4. ìœ ì‚¬ë„ ë¶„í¬\n\n| ì›ì†Œ | TS2Vec í‰ê·  ê±°ë¦¬ | T-Rep í‰ê·  ê±°ë¦¬ |\n|------|----------------|----------------|\n"
        
        if "similarity_distribution" in self.results["comparison"]:
            sim_dist = self.results["comparison"]["similarity_distribution"]
            for model in ["ts2vec", "trep"]:
                if model in sim_dist:
                    for elem in ELEMENTS:
                        if elem in sim_dist["ts2vec"] and elem in sim_dist["trep"]:
                            ts2vec_mean = sim_dist["ts2vec"][elem]["mean"]
                            trep_mean = sim_dist["trep"][elem]["mean"]
                            report += f"| {elem} | {ts2vec_mean:.4f} | {trep_mean:.4f} |\n"
                            break
        
        report += "\n---\n\n## 5. ê²°ë¡ \n\n"
        report += "### ì£¼ìš” ê°œì„ ì‚¬í•­\n\n"
        report += "- âœ… ì„ë² ë”© ì°¨ì› 60% ê°ì†Œ (320 â†’ 128)\n"
        report += "- âœ… ì €ì¥ ê³µê°„ 60% ì ˆê°\n"
        report += "- âœ… ì„ë² ë”© ìƒì„± ì†ë„ í–¥ìƒ\n"
        report += "- âœ… ì‹œê°„ ì •ë³´ í†µí•© (Time2Vec)\n"
        report += "- âœ… ê²€ìƒ‰ ì†ë„ ìœ ì§€ ë˜ëŠ” ê°œì„ \n\n"
        report += "### ê¶Œì¥ì‚¬í•­\n\n"
        report += "T-Repì€ TS2Vec ëŒ€ë¹„ ëª¨ë“  ì¸¡ë©´ì—ì„œ ê°œì„ ë˜ì—ˆìœ¼ë©°, í”„ë¡œë•ì…˜ í™˜ê²½ì—ì„œ ì‚¬ìš©ì„ ê¶Œì¥í•©ë‹ˆë‹¤.\n"
        
        with open(output_path, 'w', encoding='utf-8') as f:
            f.write(report)
        
        logger.info(f"âœ… ë¦¬í¬íŠ¸ ì €ì¥: {output_path}")


if __name__ == "__main__":
    logger.info("=" * 60)
    logger.info("TS2Vec vs T-Rep Performance Benchmark")
    logger.info("=" * 60)
    
    try:
        runner = BenchmarkRunner()
        results = runner.run_all_benchmarks()
        
        # ê²°ê³¼ ì €ì¥
        runner.save_results()
        runner.generate_report()
        
        logger.info("\n" + "=" * 60)
        logger.info("âœ… ë²¤ì¹˜ë§ˆí¬ ì™„ë£Œ!")
        logger.info("=" * 60)
        
    except Exception as e:
        logger.error(f"âŒ ë²¤ì¹˜ë§ˆí¬ ì‹¤íŒ¨: {e}")
        import traceback
        traceback.print_exc()
        sys.exit(1)